{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.73418578 0.75995848], Updated Bias: 0.8822757777502408\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.73418578 0.65995848], Updated Bias: 0.7822757777502408\n",
      " Inputs: [1 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.63418578 0.65995848], Updated Bias: 0.6822757777502408\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.63418578 0.65995848], Updated Bias: 0.6822757777502408\n",
      "\n",
      "Epoch 2/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.63418578 0.65995848], Updated Bias: 0.5822757777502409\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.63418578 0.55995848], Updated Bias: 0.4822757777502409\n",
      " Inputs: [1 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.53418578 0.55995848], Updated Bias: 0.3822757777502409\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.53418578 0.55995848], Updated Bias: 0.3822757777502409\n",
      "\n",
      "Epoch 3/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.53418578 0.55995848], Updated Bias: 0.28227577775024093\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.53418578 0.45995848], Updated Bias: 0.18227577775024092\n",
      " Inputs: [1 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.43418578 0.45995848], Updated Bias: 0.08227577775024092\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.43418578 0.45995848], Updated Bias: 0.08227577775024092\n",
      "\n",
      "Epoch 4/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.43418578 0.45995848], Updated Bias: -0.017724222249759086\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.43418578 0.35995848], Updated Bias: -0.11772422224975909\n",
      " Inputs: [1 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.33418578 0.35995848], Updated Bias: -0.2177242222497591\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.33418578 0.35995848], Updated Bias: -0.2177242222497591\n",
      "\n",
      "Epoch 5/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.33418578 0.35995848], Updated Bias: -0.2177242222497591\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.33418578 0.25995848], Updated Bias: -0.3177242222497591\n",
      " Inputs: [1 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      "\n",
      "Epoch 6/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      "\n",
      "Epoch 7/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      "\n",
      "Epoch 8/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      "\n",
      "Epoch 9/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      "\n",
      "Epoch 10/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.23418578 0.25995848], Updated Bias: -0.41772422224975914\n",
      "\n",
      "Testing the model:\n",
      " Inputs: [0 0], Predicted Output: 0\n",
      " Inputs: [0 1], Predicted Output: 0\n",
      " Inputs: [1 0], Predicted Output: 0\n",
      " Inputs: [1 1], Predicted Output: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Define the activation function (Heaviside Step function)\n",
    "def activation_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "# Step 2: Define the perceptron model\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "        # Initialize weights randomly (You can also set custom weights for demonstration)\n",
    "        self.weights = np.random.rand(2)  # Two weights for two inputs\n",
    "        self.bias = np.random.rand()      # Bias term\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    # Step 3: Perceptron prediction (forward pass)\n",
    "    def predict(self, inputs):\n",
    "        # Calculate the weighted sum of inputs + bias\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "        # Apply the activation function\n",
    "        return activation_function(weighted_sum)\n",
    "\n",
    "    # Step 4: Train the perceptron using the training data\n",
    "    def train(self, training_inputs, labels, epochs=20):\n",
    "        for epoch in range(epochs):\n",
    "            print(f'Epoch {epoch+1}/{epochs}:')\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                # Make a prediction\n",
    "                prediction = self.predict(inputs)\n",
    "                # Calculate the error (difference between predicted and actual label)\n",
    "                error = label - prediction\n",
    "                # Update the weights and bias using the perceptron learning rule\n",
    "                self.weights += self.learning_rate * error * inputs\n",
    "                self.bias += self.learning_rate * error\n",
    "                print(f' Inputs: {inputs}, Prediction: {prediction}, Actual: {label}, Error: {error}')\n",
    "                print(f' Updated Weights: {self.weights}, Updated Bias: {self.bias}')\n",
    "            print()\n",
    "\n",
    "# Step 5: Prepare the dataset for the AND gate (Truth Table)\n",
    "training_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "labels = np.array([0, 0, 0, 1])  # AND gate outputs\n",
    "\n",
    "# Step 6: Initialize the perceptron model\n",
    "perceptron = Perceptron(learning_rate=0.1)\n",
    "\n",
    "# Step 7: Train the perceptron model\n",
    "perceptron.train(training_inputs, labels, epochs=10)\n",
    "\n",
    "# Step 8: Test the perceptron model\n",
    "print('Testing the model:')\n",
    "for inputs in training_inputs:\n",
    "    output = perceptron.predict(inputs)\n",
    "    print(f' Inputs: {inputs}, Predicted Output: {output}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Weight and Bias Changes During Training:**\n",
    "Weights and bias are updated based on the error between the predicted and actual output. The update rule is:\n",
    "\\[\n",
    "\\text{weights}_{\\text{new}} = \\text{weights}_{\\text{old}} + \\text{learning rate} \\times \\text{error} \\times \\text{input}\n",
    "\\]\n",
    "\\[\n",
    "\\text{bias}_{\\text{new}} = \\text{bias}_{\\text{old}} + \\text{learning rate} \\times \\text{error}\n",
    "\\]\n",
    "As training progresses, the weights and bias adjust to minimize the error, ensuring correct predictions for the AND gate truth table.\n",
    "\n",
    "### 2. **Learning AND Logic with a Linear Decision Boundary:**\n",
    "Yes, the perceptron can successfully learn the AND logic because the AND gate is linearly separable. The perceptron finds weights and bias to define a linear boundary that separates the output classes (0 and 1) correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: 0.09501909878104661\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: 0.09501909878104661\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: 0.09501909878104661\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: 0.09501909878104661\n",
      "\n",
      "Epoch 2/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      "\n",
      "Epoch 3/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      "\n",
      "Epoch 4/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      "\n",
      "Epoch 5/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      "\n",
      "Epoch 6/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      "\n",
      "Epoch 7/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      "\n",
      "Epoch 8/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      "\n",
      "Epoch 9/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      "\n",
      "Epoch 10/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.2592929  0.67005697], Updated Bias: -0.004980901218953393\n",
      "\n",
      "Testing the model:\n",
      " Inputs: [0 0], Predicted Output: 0\n",
      " Inputs: [0 1], Predicted Output: 1\n",
      " Inputs: [1 0], Predicted Output: 1\n",
      " Inputs: [1 1], Predicted Output: 1\n"
     ]
    }
   ],
   "source": [
    "training_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "labels = np.array([0, 1, 1, 1])  # OR gate outputs\n",
    "\n",
    "# Step 6: Initialize the perceptron model\n",
    "perceptron = Perceptron(learning_rate=0.1)\n",
    "\n",
    "# Step 7: Train the perceptron model\n",
    "perceptron.train(training_inputs, labels, epochs=10)\n",
    "\n",
    "# Step 8: Test the perceptron model\n",
    "print('Testing the model:')\n",
    "for inputs in training_inputs:\n",
    "    output = perceptron.predict(inputs)\n",
    "    print(f' Inputs: {inputs}, Predicted Output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Necessary Weight Changes for OR Gate Logic:**\n",
    "The perceptron's weights and bias must adjust to ensure that it outputs **1** when at least one input is 1. Weights increase when the prediction is incorrect, encouraging the model to correctly classify `(0, 1)`, `(1, 0)`, and `(1, 1)` as 1.\n",
    "\n",
    "### 2. **Linear Decision Boundary for OR Gate:**\n",
    "The linear decision boundary is a straight line that separates the input `(0, 0)` (output 0) from the inputs `(0, 1)`, `(1, 0)`, and `(1, 1)` (output 1). This boundary ensures correct classification for the OR gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.91886217 0.34781154], Updated Bias: 0.7057034600668574\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.91886217 0.24781154], Updated Bias: 0.6057034600668574\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.91886217 0.24781154], Updated Bias: 0.6057034600668574\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.81886217 0.14781154], Updated Bias: 0.5057034600668574\n",
      "\n",
      "Epoch 2/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.81886217 0.14781154], Updated Bias: 0.4057034600668574\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.81886217 0.04781154], Updated Bias: 0.30570346006685745\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.81886217 0.04781154], Updated Bias: 0.30570346006685745\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.71886217 -0.05218846], Updated Bias: 0.20570346006685744\n",
      "\n",
      "Epoch 3/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.71886217 -0.05218846], Updated Bias: 0.10570346006685744\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.71886217 -0.15218846], Updated Bias: 0.00570346006685743\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.71886217 -0.15218846], Updated Bias: 0.00570346006685743\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.61886217 -0.25218846], Updated Bias: -0.09429653993314258\n",
      "\n",
      "Epoch 4/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.61886217 -0.25218846], Updated Bias: -0.09429653993314258\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.61886217 -0.25218846], Updated Bias: -0.09429653993314258\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.61886217 -0.25218846], Updated Bias: -0.09429653993314258\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      "\n",
      "Epoch 5/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      "\n",
      "Epoch 6/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      "\n",
      "Epoch 7/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      "\n",
      "Epoch 8/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      "\n",
      "Epoch 9/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      "\n",
      "Epoch 10/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.51886217 -0.35218846], Updated Bias: -0.19429653993314258\n",
      "\n",
      "Testing the model:\n",
      " Inputs: [0 0], Predicted Output: 0\n",
      " Inputs: [0 1], Predicted Output: 0\n",
      " Inputs: [1 0], Predicted Output: 1\n",
      " Inputs: [1 1], Predicted Output: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Truth table for the AND-NOT gate\n",
    "training_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "labels = np.array([0, 0, 1, 0])  # AND-NOT gate outputs\n",
    "\n",
    "# Step 2: Initialize the perceptron model (reusing previous perceptron class)\n",
    "perceptron = Perceptron(learning_rate=0.1)\n",
    "\n",
    "# Step 3: Train the perceptron on the AND-NOT gate truth table\n",
    "perceptron.train(training_inputs, labels, epochs=10)\n",
    "\n",
    "# Step 4: Test the perceptron model\n",
    "print('Testing the model:')\n",
    "for inputs in training_inputs:\n",
    "    output = perceptron.predict(inputs)\n",
    "    print(f' Inputs: {inputs}, Predicted Output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Perceptron's Weight Configuration After Training for AND-NOT Gate:**\n",
    "After training, the weights will be adjusted so that the perceptron outputs **1** when the first input is 1 and the second input is 0. Typically, the weight for the first input will be positive, while the weight for the second input will be negative, ensuring correct classification.\n",
    "\n",
    "### 2. **Handling Cases Where Both Inputs Are 1 or 0:**\n",
    "- **Both inputs are 1**: The perceptron outputs **0** because the second input's negative weight cancels the first input's positive effect.\n",
    "- **Both inputs are 0**: The perceptron outputs **0** as the weighted sum of inputs will be below the activation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.43687508 0.71122398], Updated Bias: 0.4349649244078614\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.43687508 0.71122398], Updated Bias: 0.4349649244078614\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.43687508 0.71122398], Updated Bias: 0.4349649244078614\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.33687508 0.61122398], Updated Bias: 0.3349649244078614\n",
      "\n",
      "Epoch 2/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.33687508 0.61122398], Updated Bias: 0.2349649244078614\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.33687508 0.61122398], Updated Bias: 0.2349649244078614\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.33687508 0.61122398], Updated Bias: 0.2349649244078614\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.23687508 0.51122398], Updated Bias: 0.1349649244078614\n",
      "\n",
      "Epoch 3/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.23687508 0.51122398], Updated Bias: 0.03496492440786139\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.23687508 0.51122398], Updated Bias: 0.03496492440786139\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.23687508 0.51122398], Updated Bias: 0.03496492440786139\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.13687508 0.41122398], Updated Bias: -0.06503507559213861\n",
      "\n",
      "Epoch 4/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.13687508 0.41122398], Updated Bias: -0.06503507559213861\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.13687508 0.41122398], Updated Bias: -0.06503507559213861\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.13687508 0.41122398], Updated Bias: -0.06503507559213861\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.03687508 0.31122398], Updated Bias: -0.16503507559213862\n",
      "\n",
      "Epoch 5/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.03687508 0.31122398], Updated Bias: -0.16503507559213862\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.03687508 0.31122398], Updated Bias: -0.16503507559213862\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [0.13687508 0.31122398], Updated Bias: -0.06503507559213861\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.03687508 0.21122398], Updated Bias: -0.16503507559213862\n",
      "\n",
      "Epoch 6/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.03687508 0.21122398], Updated Bias: -0.16503507559213862\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.03687508 0.21122398], Updated Bias: -0.16503507559213862\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [0.13687508 0.21122398], Updated Bias: -0.06503507559213861\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.03687508 0.11122398], Updated Bias: -0.16503507559213862\n",
      "\n",
      "Epoch 7/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.03687508 0.11122398], Updated Bias: -0.16503507559213862\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [0.03687508 0.21122398], Updated Bias: -0.06503507559213861\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [0.13687508 0.21122398], Updated Bias: 0.03496492440786139\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.03687508 0.11122398], Updated Bias: -0.06503507559213861\n",
      "\n",
      "Epoch 8/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.03687508 0.11122398], Updated Bias: -0.06503507559213861\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.03687508 0.11122398], Updated Bias: -0.06503507559213861\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [0.13687508 0.11122398], Updated Bias: 0.03496492440786139\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.03687508 0.01122398], Updated Bias: -0.06503507559213861\n",
      "\n",
      "Epoch 9/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.03687508 0.01122398], Updated Bias: -0.06503507559213861\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [0.03687508 0.11122398], Updated Bias: 0.03496492440786139\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.03687508 0.11122398], Updated Bias: 0.03496492440786139\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.06312492  0.01122398], Updated Bias: -0.06503507559213861\n",
      "\n",
      "Epoch 10/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [-0.06312492  0.01122398], Updated Bias: -0.06503507559213861\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [-0.06312492  0.11122398], Updated Bias: 0.03496492440786139\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [0.03687508 0.11122398], Updated Bias: 0.1349649244078614\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.06312492  0.01122398], Updated Bias: 0.03496492440786139\n",
      "\n",
      "Testing the model:\n",
      " Inputs: [0 0], Predicted Output: 1\n",
      " Inputs: [0 1], Predicted Output: 1\n",
      " Inputs: [1 0], Predicted Output: 0\n",
      " Inputs: [1 1], Predicted Output: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Truth table for the XOR gate\n",
    "training_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "labels = np.array([0, 1, 1, 0])  # XOR gate outputs\n",
    "\n",
    "# Step 2: Initialize the perceptron model (reusing previous Perceptron class)\n",
    "perceptron = Perceptron(learning_rate=0.1)\n",
    "\n",
    "# Step 3: Train the perceptron on the XOR gate truth table\n",
    "perceptron.train(training_inputs, labels, epochs=10)\n",
    "\n",
    "# Step 4: Test the perceptron model\n",
    "print('Testing the model:')\n",
    "for inputs in training_inputs:\n",
    "    output = perceptron.predict(inputs)\n",
    "    print(f' Inputs: {inputs}, Predicted Output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Why Does the Single Layer Perceptron Struggle to Classify the XOR Gate?**\n",
    "The Single Layer Perceptron struggles with the XOR gate because it is **not linearly separable**. This means that a single straight line cannot divide the input space into two classes (0 and 1). The XOR function requires a more complex decision boundary that cannot be achieved with only one layer.\n",
    "\n",
    "### 2. **Modifications to Handle the XOR Gate Correctly:**\n",
    "To correctly classify the XOR gate, the following modifications can be made:\n",
    "- **Use a Multi-Layer Perceptron (MLP)**: Introduce one or more hidden layers to allow for non-linear transformations.\n",
    "- **Increase the Number of Neurons**: Add more neurons in the hidden layer(s) to capture complex patterns.\n",
    "- **Train with Sufficient Epochs**: Increase the number of training epochs to ensure proper convergence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
